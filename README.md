# ğŸš€ BeyondChats Content Engine

A robust Node.js automation engine that scrapes blog content, enhances it using AI (Google Gemini), and publishes it via a RESTful API.

## ğŸ“‹ Overview

This project consists of two main automated workflows:

1. **Phase 1 (Scraper):** Crawls the *BeyondChats* blog to find and store the 5 oldest articles.
2. **Phase 2 (AI Pipeline):** Takes the latest stored article, researches related high-ranking content on Google, and uses an LLM (Google Gemini) to rewrite and enhance the article with improved formatting and citations.

## âœ¨ Features

* **Smart Pagination:** Automatically traverses blog pagination to find the oldest content.
* **Fail-Fast Architecture:** The pipeline aborts immediately if data is missing or scraping fails, preventing bad data from entering the database.
* **AI-Powered Rewriting:** Uses **Google Gemini 1.5/Pro** to rewrite content with HTML formatting.
* **Research Automation:** Searches Google Custom Search API to find relevant reference material.
* **Robust Scraping:** Uses `@mozilla/readability` and `JSDOM` with `VirtualConsole` to parse external websites cleanly.
* **Error Handling:** Centralized `ApiError` and `asyncHandler` for clean controller logic.

## ğŸ› ï¸ Tech Stack

* **Runtime:** Node.js
* **Database:** MongoDB (Mongoose)
* **AI Model:** Google Gemini (via `@google/generative-ai`)
* **Scraping:** JSDOM, Mozilla Readability, Axios
* **Search:** Google Custom Search JSON API

## âš™ï¸ Prerequisites

Before running the project, ensure you have:

1. **Node.js** (v18+ recommended)
2. **MongoDB** (Local or Atlas URL)
3. **API Keys**:
* **Google Custom Search API Key** (for searching the web)
* **Google CSE ID** (Custom Search Engine ID)
* **Google Gemini API Key** (for AI generation)



## ğŸš€ Installation & Setup

1. **Clone the repository** (if applicable) or navigate to your project folder.
2. **Install Dependencies**
```bash
npm install

```


3. **Configure Environment Variables**
Create a `.env` file in the root directory and add the following:
```env
PORT=5050
MONGO_URI=mongodb+srv://<user>:<password>@cluster.mongodb.net/beyondchats

# Google Search Config
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_CSE_ID=your_cse_id_here

# AI Config
GEMINI_API_KEY=your_gemini_api_key_here

```



## ğŸƒâ€â™‚ï¸ How to Run

### 1. Start the API Server

This keeps your REST API running so you can access the data via browser or Postman.

```bash
npm run dev
# OR
node src/app.js

```

* Server runs at: `http://localhost:5050`

### 2. Run the Automation Workflow

This runs **Phase 1** (Scraping) followed immediately by **Phase 2** (AI Enhancement).

```bash
node src/runFullWorkflow.js

```

**What happens when you run this?**

1. **Scraper** connects to MongoDB.
2. It traverses `beyondchats.com` to find the last page.
3. It saves the 5 oldest articles to the database.
4. **Pipeline** picks the latest article from the DB.
5. It searches Google for that title.
6. It scrapes 2 valid external sources for context.
7. It uses Gemini to rewrite the article.
8. It saves a **new** article (Total DB count: 6).

## ğŸ“‚ Project Structure

```
src/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ db.js                 # MongoDB Connection logic
â”œâ”€â”€ controllers/
â”‚   â””â”€â”€ articleController.js  # API logic (get, create)
â”œâ”€â”€ middlewares/
â”‚   â””â”€â”€ errorMiddleware.js    # Global error handling
â”œâ”€â”€ models/
â”‚   â””â”€â”€ article.js            # Mongoose Schema
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ runPipeline.js        # Phase 2: AI Enhancement Logic
â”œâ”€â”€ routes/
â”‚   â””â”€â”€ articleRoutes.js      # Express Routes
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ beyondChatsScraper.js # Phase 1: Blog Scraper
â”‚   â”œâ”€â”€ googleSearchService.js# Google API integration
â”‚   â”œâ”€â”€ llmService.js         # Gemini AI integration
â”‚   â””â”€â”€ scraperService.js     # Generic JSDOM/Readability scraper
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ ApiError.js           # Custom Error Class
â”‚   â””â”€â”€ asyncHandler.js       # Wrapper for async controllers
â”œâ”€â”€ app.js                    # Main Express App
â””â”€â”€ runFullWorkflow.js        # Master script to run everything

```

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
| --- | --- | --- |
| `GET` | `/api/articles` | Fetch all articles (sorted by newest) |
| `GET` | `/api/articles/latest` | Fetch the single latest article |
| `POST` | `/api/articles` | Manually create a new article |

## ğŸ›¡ï¸ Troubleshooting

* **429 Quota Exceeded:** Your OpenAI/Gemini free tier might be exhausted. The code is currently set to use `gemini-pro` (free tier friendly).
* **403 Forbidden (Scraping):** Some sites (like Reddit) block scrapers. The pipeline is designed to skip these and try the next available link from Google results.
